# 优化版近邻搜索算法比较实验报告

## 1. 引言

本实验旨在实现并评估三种常见的最近邻搜索算法：暴力搜索、K-D树搜索和最佳优先搜索（BBF）。通过在一系列标准化的数据集上测试这些算法，我们旨在比较它们在查询时间、内存使用和搜索准确率方面的性能。此外，本文档还详细记录了从初始实现 (`main.py`) 到优化版本 (`optimized_main.py`) 的性能提升过程，包括数据读取、内存测量、并行化处理等方面的改进，以及对实验过程中遇到的问题（如内存测量出现负值）的分析与解决。


## 2. 性能评估指标

*   **查询时间 (Query Time)**: 执行一次最近邻搜索所需的平均时间，单位为微秒 (µs)。时间越短越好。
*   **内存使用 (Memory Usage)**: 执行一次搜索算法（不包括数据加载和K-D树构建本身）所额外消耗的内存量，单位为字节 (bytes)。通过比较算法执行前后的进程RSS（Resident Set Size）差值得到。消耗越少越好。
*   **准确率 (Accuracy)**: 对于K-D树和BBF算法，其搜索结果与暴力搜索得到的真实最近邻的距离之比。计算公式为 `暴力搜索距离 / 算法搜索距离`。理想情况下，比值为1。对于BBF等近似算法，比值可能大于1。通常，如果比值略大于1（例如，在1.0到1.1之间），可以认为近似效果尚可。越接近1越好。
*   **K-D树构建时间 (Build Time)**: 构建K-D树所需的时间，单位为秒 (s)。

## 3. 从 `main.py` 到 `optimized_main.py` 的优化历程

初始版本的 `main.py` 在处理大规模数据集时（如本项目中的100个7.6MB的文件，每个包含10万个8维数据点）暴露出明显的性能瓶颈，每个文件的处理时间远超预期。为了提升效率和实验的严谨性，进行了一系列优化，形成了 `optimized_main.py`。

### 3.1. 初步性能瓶颈分析 (基于 `main.py`)

*   **数据读取缓慢**: 逐行读取文本文件并转换为浮点数数组效率低下。
*   **内存测量开销大且不精确**: 使用 `tracemalloc` 模块进行内存分配跟踪，虽然详细但对于测量短时函数执行的内存增量来说开销过大，且易受其他Python内部活动干扰。
*   **串行执行**: 所有查询点和所有算法的评估都是串行执行的，未能利用多核CPU的并行处理能力。
*   **缺乏进度反馈和健壮性**: 长时间运行时，用户无法了解进度；若意外中断，所有已完成工作将丢失。
*   **图表中文显示问题**: Matplotlib默认配置下中文标题和标签会显示为方框。

### 3.2. 数据读取优化

*   **批量读取**: `optimized_main.py` 中的 `read_data_from_file` 函数改用 `np.fromstring(file.readline().strip(), sep=' ')`，它能更高效地从单行文本中解析出数值数组，相较于原先的 `map(float, ...)` 和逐元素赋值，速度有显著提升。
*   **数据类型调整**: 数据点和查询点的数据类型从默认的 `float64` 改为 `np.float32`。对于本项目的数据范围和精度要求，`float32` 足够使用，且能将数据占用的内存减少一半，从而降低内存带宽压力，间接提升I/O和计算速度。
*   **预分配数组**: 使用 `np.zeros`预分配NumPy数组，避免了Python列表在添加元素时可能发生的动态内存重新分配和拷贝开销。

### 3.3. 内存测量优化与严谨性

*   **切换到 `psutil`**: `optimized_main.py` 使用 `psutil.Process(os.getpid()).memory_info().rss` 来获取进程的常驻集大小(RSS)。这种方法直接查询操作系统层面的内存占用，相比 `tracemalloc`，开销更小，更适合测量函数执行前后整体内存的变化。
*   **引入垃圾回收 `gc.collect()`**: 为了提高RSS差值测量的稳定性，在新的辅助函数 `_measure_algo_performance` 中，在获取算法执行前和执行后的RSS读数之前都强制调用了 `gc.collect()`。这有助于：
    1.  在算法执行前清理掉Python环境中可能存在的未被回收的临时对象，使得初始内存读数 (`mem_before`) 更能代表一个"干净"的基线。
    2.  在算法执行后再次清理，确保算法执行过程中产生的临时对象（如果它们在算法结束时已变为垃圾）被回收，使得结束内存读数 (`mem_after`) 更能反映算法稳定状态下的内存占用。
*   **保留原始内存差值 (负值处理)**: 计算出的内存差值 (`mem_delta = mem_after - mem_before`) **被如实记录**，即使它是负数。负值表示在该测量窗口内，由于Python的GC活动或OS层面的内存整理，进程的总体RSS减少了。这在测量内存占用很小且执行时间很短的函数时是可能发生的，尤其是在GC被显式调用后。**不修改原始测量数据是保证实验结果严谨性的关键**。原始的、可能为负的内存差值会被记录在 `all_results.csv` 中，并用于计算 `summary_results.csv` 中的平均内存使用。
*   **绘图时的负值处理**: 仅在 `plot_results` 函数中绘制内存使用图表时，对从 `summary_df` 中获取的平均内存使用数据（例如 `summary_df['avg_bf_memory']`）使用 `np.maximum(0, series_data)` 进行处理。这意味着图表上不会显示负的内存条（负内存占用在图上无实际意义），但CSV文件中的原始数据和计算出的平均值将保持其原始形态（可能为负）。

### 3.4. 并行化处理

*   `optimized_main.py` 中的 `evaluate_algorithms` 函数引入了 `multiprocessing.Pool`。当查询点数量较多时（当前设置为 >= 4），它会创建一个进程池（进程数量限制为CPU核心数和4之间的较小值，以避免过多开销），并将单个查询点的评估任务 (`evaluate_single_query`) 分发给不同的进程并行执行。这能显著缩短处理多个查询所需的总时间，尤其是在多核CPU上。
*   使用 `functools.partial` 来固定 `evaluate_single_query` 的部分参数，简化了向 `pool.starmap` 的传递。

### 3.5. 进度反馈与健壮性

*   **处理耗时打印**: `process_data_files` 函数现在会打印每个数据文件开始处理的信息，以及完成处理后的耗时。
*   **中间结果保存**: 为了防止长时间运行（例如处理全部100个文件）因意外中断而丢失所有进度，程序现在每处理完10个文件，就会将当前的汇总结果 (`summary_results`) 保存到一个临时的CSV文件（如 `summary_results_temp_10.csv`, `summary_results_temp_20.csv` 等）中。
*   **总体计时**: 程序结束时会打印总运行时间。

### 3.6. 中文显示与国际化

*   **中文字体配置**: `configure_matplotlib_chinese` 函数尝试设置Matplotlib的 `font.sans-serif` 和 `axes.unicode_minus` 参数，以支持在图表中使用中文字体（如SimHei）。
*   **自动回退与手动切换**: 如果中文字体配置失败（例如系统缺少指定字体），程序会自动将标签和标题切换为英文。此外，`optimized_main.py` 和新增的 `plot_summary.py` 都提供了 `--english` 命令行参数，允许用户强制使用英文标签，增加了在不同环境下的可用性。
*   **标签字典**: `plot_results` 函数使用一个 `labels` 字典来管理所有图表的文本元素，方便根据 `USE_ENGLISH_LABELS` 全局变量切换语言。


## 使用方法 (`optimized_main.py`)

```bash
python optimized_main.py [options]
```

### 命令行选项

- `--data_dir`: 数据文件目录（默认: ./data）
- `--max_files`: 处理的最大文件数量（默认: 100）
- `--max_queries`: 每个文件处理的最大查询点数（默认: 100）
- `--bbf_t`: BBF搜索访问的最大叶节点数（默认: 200）
- `--no_multiprocessing`: 禁用多进程处理
- `--english`: 使用英文标签和标题

### 示例

处理前10个文件，每个文件50个查询点:
```bash
python optimized_main.py --max_files 10 --max_queries 50
```

禁用多进程处理:
```bash
python optimized_main.py --no_multiprocessing
```

## 中间结果保存

为防止长时间运行中断导致数据丢失，每处理10个文件会保存一次中间结果:
- `results/summary_results_temp_10.csv`
- `results/summary_results_temp_20.csv`
- ...等

## 注意事项

1. 多进程模式下，使用的是共享内存模型，内存使用会略微增加。
2. 处理大型数据集时，建议确保系统有足够的内存空间。
3. 如果程序占用过多内存，可以考虑减小`max_queries`参数值。 